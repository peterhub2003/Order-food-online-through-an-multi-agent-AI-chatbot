ğŸœ Thang Food Assistant - Multi-Agent AI Chatbot

ğŸ“– Giá»›i thiá»‡u

Thang Food Assistant lÃ  má»™t há»‡ thá»‘ng chatbot Ä‘áº·t mÃ³n Äƒn thÃ´ng minh tháº¿ há»‡ má»›i, Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n trÃºc Multi-Agent (Äa tÃ¡c tá»­). KhÃ¡c vá»›i cÃ¡c chatbot truyá»n thá»‘ng dá»±a trÃªn ká»‹ch báº£n cá»©ng, há»‡ thá»‘ng nÃ y sá»­ dá»¥ng LLM (Large Language Model) cháº¡y cá»¥c bá»™ (Local Inference) Ä‘á»ƒ suy luáº­n, láº­p káº¿ hoáº¡ch vÃ  thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ phá»©c táº¡p.

Há»‡ thá»‘ng bao gá»“m 4 thÃ nh pháº§n chÃ­nh hoáº¡t Ä‘á»™ng phá»‘i há»£p:

- ChatUI (Frontend): Giao diá»‡n chat hiá»‡n Ä‘áº¡i, há»— trá»£ xÃ¡c thá»±c ngÆ°á»i dÃ¹ng.

- Multi-Agent System: Bá»™ nÃ£o trung tÃ¢m sá»­ dá»¥ng LangGraph (Orchestrator, Tool Agent, Synthesis Agent).

- MCP Server: Chuáº©n hÃ³a giao tiáº¿p cÃ´ng cá»¥ (Model Context Protocol).

- Backend Service: Há»‡ thá»‘ng quáº£n lÃ½ nhÃ  hÃ ng (Menu, ÄÆ¡n hÃ ng, User) viáº¿t báº±ng FastAPI.

TÃ­nh nÄƒng ná»•i báº­t

ğŸ¤– Local LLM: Cháº¡y hoÃ n toÃ n offline vá»›i Ollama (Llama 3, Qwen 2.5, GPT-OSS...), Ä‘áº£m báº£o quyá»n riÃªng tÆ° dá»¯ liá»‡u.

ğŸ§  Reasoning & Planning: Tá»± Ä‘á»™ng láº­p káº¿ hoáº¡ch Ä‘a bÆ°á»›c Ä‘á»ƒ xá»­ lÃ½ yÃªu cáº§u (Há»i giÃ¡ -> TÃ¬m ID -> Táº¡o Ä‘Æ¡n -> ThÃªm mÃ³n -> TÃ­nh tiá»n).

ğŸ› ï¸ Tool Use chÃ­nh xÃ¡c: Sá»­ dá»¥ng cÃ´ng cá»¥ Ä‘á»ƒ tra cá»©u DB vÃ  tÃ­nh toÃ¡n tiá»n nong chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i, khÃ´ng bá»‹ áº£o giÃ¡c (hallucination).

ğŸ”„ Quáº£n lÃ½ ngá»¯ cáº£nh: Ghi nhá»› thÃ´ng tin khÃ¡ch hÃ ng vÃ  giá» hÃ ng trong suá»‘t phiÃªn há»™i thoáº¡i.

âš™ï¸ YÃªu cáº§u há»‡ thá»‘ng (Prerequisites)

Äá»ƒ cháº¡y trÆ¡n tru há»‡ thá»‘ng (Ä‘áº·c biá»‡t lÃ  mÃ´ hÃ¬nh LLM 20B+), mÃ¡y tÃ­nh cá»§a báº¡n cáº§n Ä‘Ã¡p á»©ng:

- Docker & Docker Compose: ÄÃ£ cÃ i Ä‘áº·t.
- Git: ÄÃ£ cÃ i Ä‘áº·t.
- Pháº§n cá»©ng (Khuyáº¿n nghá»‹):
  - RAM: Tá»‘i thiá»ƒu 16GB.
  - GPU: NVIDIA GPU vá»›i tá»‘i thiá»ƒu 16GB VRAM (Náº¿u cháº¡y mode GPU).

Náº¿u chá»‰ dÃ¹ng CPU, tá»‘c Ä‘á»™ pháº£n há»“i sáº½ cháº­m hÆ¡n Ä‘Ã¡ng ká»ƒ.

ğŸš€ HÆ°á»›ng dáº«n CÃ i Ä‘áº·t & Sá»­ dá»¥ng

LÃ m theo cÃ¡c bÆ°á»›c sau Ä‘á»ƒ khá»Ÿi cháº¡y há»‡ thá»‘ng:

BÆ°á»›c 1: Táº£i mÃ£ nguá»“n

``` bash
git clone https://github.com/peterhub2003/Order-food-online-through-an-multi-agent-AI-chatbot.git
cd Order-food-online-through-an-multi-agent-AI-chatbot
``` 

BÆ°á»›c 2: Khá»Ÿi cháº¡y háº¡ táº§ng Docker

TÃ¹y thuá»™c vÃ o pháº§n cá»©ng cá»§a báº¡n, hÃ£y chá»n lá»‡nh phÃ¹ há»£p:

ğŸ‘‰ Lá»±a chá»n A: Náº¿u báº¡n cÃ³ NVIDIA GPU (Khuyáº¿n nghá»‹)
Sá»­ dá»¥ng file cáº¥u hÃ¬nh há»— trá»£ GPU Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t Ollama:

``` bash
docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d --build
```


ğŸ‘‰ Lá»±a chá»n B: Náº¿u báº¡n chá»‰ dÃ¹ng CPU
Sá»­ dá»¥ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh:

``` bash
docker compose -f docker-compose.yml up -d --build
```


BÆ°á»›c 3: Táº£i vÃ  cháº¡y MÃ´ hÃ¬nh AI (Ollama)

ChÃºng tÃ´i cung cáº¥p script tá»± Ä‘á»™ng Ä‘á»ƒ pull vÃ  cháº¡y model. Máº·c Ä‘á»‹nh há»‡ thá»‘ng sá»­ dá»¥ng mÃ´ hÃ¬nh gpt-oss:20b (hoáº·c model tÃ¹y chá»‰nh Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong script).

Cháº¡y vá»›i model máº·c Ä‘á»‹nh:

``` bash
chmod +x run_ollama_gpt_oss.sh
./run_ollama_gpt_oss.sh
```


Hoáº·c cháº¡y vá»›i model khÃ¡c (VÃ­ dá»¥: llama3):

``` bash
./run_ollama_gpt_oss.sh llama3
```


LÆ°u Ã½: QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t vÃ i phÃºt tÃ¹y thuá»™c vÃ o tá»‘c Ä‘á»™ máº¡ng Ä‘á»ƒ táº£i model vá».

BÆ°á»›c 4: Khá»Ÿi táº¡o dá»¯ liá»‡u máº«u (Seed Database)

Äá»ƒ chatbot cÃ³ dá»¯ liá»‡u vá» Menu (CÆ¡m Táº¥m, Phá»Ÿ...), User vÃ  cÃ¡c thiáº¿t láº­p ban Ä‘áº§u, hÃ£y cháº¡y lá»‡nh seed:

``` bash
docker compose exec backend python -m app.seed
```


BÆ°á»›c 5: Tráº£i nghiá»‡m

Má»Ÿ trÃ¬nh duyá»‡t web vÃ  truy cáº­p vÃ o Ä‘á»‹a chá»‰:

ğŸ‘‰ http://localhost:3000

- ÄÄƒng kÃ½ tÃ i khoáº£n má»›i (Register).

- ÄÄƒng nháº­p (Login).

- Báº¯t Ä‘áº§u chat Ä‘áº·t mÃ³n (VÃ­ dá»¥: "Cho tÃ´i 2 pháº§n CÆ¡m Táº¥m vá» 12 LÃª Duáº©n").


